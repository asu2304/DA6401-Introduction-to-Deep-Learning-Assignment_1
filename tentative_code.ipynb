{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d62b44e-1ad7-4328-bf28-79abc09f7a5c",
   "metadata": {},
   "source": [
    "## Assignment 1: (DA6401) Introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f724bf2-8235-4553-8f20-792a4f8a023f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### installing dependencies and setting up the wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd17589-d1c5-4208-86cc-8bfa1c565200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wandb in c:\\users\\ashutosh patidar\\appdata\\roaming\\python\\python312\\site-packages (0.19.7)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\ashutosh patidar\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\anaconda3\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\anaconda3\\lib\\site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\anaconda3\\lib\\site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in c:\\anaconda3\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda3\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\ashutosh patidar\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\ashutosh patidar\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94710321-6c4c-4644-aca4-5ca13ae61672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: da24s006 (da24s006-indian-institue-of-technology-madras-) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787317cc-b28d-4c16-8bec-7c8ff2cac14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Ashutosh Patidar\\OneDrive\\Documents\\GitHub\\Assignment_1_Deep_Learning\\wandb\\run-20250306_211108-jiai6ano</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch/runs/jiai6ano' target=\"_blank\">lilac-disco-4</a></strong> to <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch/runs/jiai6ano' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch/runs/jiai6ano</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/Backprop_From_Scratch/runs/jiai6ano?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1cbfc9d23c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='Backprop_From_Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef626169-8b15-4d9a-b291-f99be0e8acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from keras.datasets import fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512bae4-b67a-410a-86ba-5fd237cc63e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Question 1(2 Marks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab56c078-c278-4fc0-818c-d2d2204d4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_labels = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7149b6f5-b38a-4dd6-912f-bab9a9b7b324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Ashutosh Patidar\\OneDrive\\Documents\\GitHub\\Assignment_1_Deep_Learning\\wandb\\run-20250306_212158-oeg7oaxd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch/runs/oeg7oaxd' target=\"_blank\">plot_unique_labels</a></strong> to <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch/runs/oeg7oaxd' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch/runs/oeg7oaxd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">plot_unique_labels</strong> at: <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch/runs/oeg7oaxd' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch/runs/oeg7oaxd</a><br> View project at: <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop-from-scratch</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250306_212158-oeg7oaxd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotted, plot_no = [], 1\n",
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "# Initialize W&B run\n",
    "wandb.init(project=\"backprop-from-scratch\", name=\"plot_unique_labels\")\n",
    "for index, label in enumerate(train_labels): \n",
    "\n",
    "    if len(plotted) == len(set(train_labels)):\n",
    "        break\n",
    "        \n",
    "    if label not in plotted: \n",
    "        plt.subplot(2, 5, plot_no)\n",
    "        plt.imshow(train_images[index], cmap='grey')\n",
    "        plotted.append(label)\n",
    "        plt.title(f'{fashion_mnist_labels[label]}', fontsize=8)\n",
    "        plt.axis(\"off\")\n",
    "        plot_no += 1\n",
    "\n",
    "# getting the final figure\n",
    "fig = plt.gcf()\n",
    "\n",
    "#loggint the figure of wandb\n",
    "wandb.log({\"unique_labels_plot\": wandb.Image(fig)})\n",
    "\n",
    "plt.show()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507f7bc-2fca-4c5b-877d-fcde8c3d8f47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Question 2(10 Marks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "c786be43-3f28-48fe-ab62-b6ee025a7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# defining a backprop_from_scratch to do all.\n",
    "class backprop_from_scratch:\n",
    "\n",
    "    # define constructor\n",
    "    def __init__(self, layer_size):\n",
    "        # initialise the neural network\n",
    "        self.weights, self.biases = [], []\n",
    "        self.num_layers = len(layer_size)\n",
    "        self.layer_sizes = layer_size\n",
    "        self.initialize_params()\n",
    "        \n",
    "    def initialize_params(self):\n",
    "        # let's use He initialization for weights and set values of bias equals to zero\n",
    "        for i in range(self.num_layers-1):\n",
    "            w = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1]) * np.sqrt(2/self.layer_sizes[i])\n",
    "            b = np.zeros((1, self.layer_sizes[i+1]))\n",
    "            self.weights.append(w) \n",
    "            self.biases.append(b) \n",
    "            \n",
    "    def forward_pass(self, data_X):\n",
    "        neuron_outputs = [data_X]\n",
    "        # pass thorugh hidden layers\n",
    "        for i in range(self.num_layers - 2): \n",
    "            \n",
    "            # print(\"ran\")\n",
    "            # print(neuron_outputs[-1].shape)\n",
    "            # print(self.weights[i].shape)\n",
    "            # print(self.biases[i].shape)\n",
    "            \n",
    "            a = np.dot(neuron_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            h = self.sigmoid(a)\n",
    "            neuron_outputs.append(h)\n",
    "        # pass thorugh the output layer\n",
    "        a = np.dot(neuron_outputs[-1], self.weights[-1]) + self.biases[-1]\n",
    "        output = self.softmax(a)\n",
    "        neuron_outputs.append(output)\n",
    "        return neuron_outputs\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        # clipping it bw -500 to 500 \n",
    "        return 1 / (1 + np.exp(-np.clip(X, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x*(1-x) \n",
    "        \n",
    "    def softmax(self, X): \n",
    "        # clipping it for numerical stability\n",
    "        exp_x = np.exp(X - np.max(X, axis = 1, keepdims=True))\n",
    "        return exp_x/np.sum(exp_x, axis = 1, keepdims=True)\n",
    "    \n",
    "    def backword_pass(self, X, y, neuron_outputs, learning_rate):\n",
    "        \n",
    "        # compute the gradient at given value of params\n",
    "        batch_size = len(X)\n",
    "        \n",
    "        # computing gradies with repect to the output layer \n",
    "        delta = neuron_outputs[-1] - y\n",
    "        \n",
    "        # computing gradient with respect to hidden layers\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            \n",
    "            dw = np.dot(neuron_outputs[i].T, delta) / batch_size\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / batch_size\n",
    "            \n",
    "            if i>0: # because computing delta for i=0 will be absolutely un-necessary.\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(neuron_outputs[i])\n",
    "\n",
    "            # making an update\n",
    "            self.weights[i] -= dw * learning_rate\n",
    "            self.biases[i] -= db * learning_rate\n",
    "        \n",
    "    # function to train the network\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate, batch_size):\n",
    "        for epoch in range(epochs): \n",
    "            # first shuffle the training data\n",
    "            # print(X_train.shape[0])\n",
    "            \n",
    "            indices = np.random.permutation(X_train.shape[0]) \n",
    "            X_train_permuted = X_train[indices]\n",
    "            y_train_permuted = y_train[indices]\n",
    "            \n",
    "            total_loss = 0\n",
    "            batch_num = 0\n",
    "            \n",
    "            # let's make a update for a mini batch\n",
    "            for i in range(0, X_train.shape[0], batch_size): \n",
    "                batch_x = X_train_permuted[i: i + batch_size]\n",
    "                batch_y = y_train_permuted[i: i + batch_size]\n",
    "                neuron_outputs = self.forward_pass(batch_x)\n",
    "                loss = -np.mean(np.sum(batch_y * np.log(neuron_outputs[-1] + 1e-10), axis = 1)) # to prevent numerical underflow\n",
    "                total_loss += loss\n",
    "                batch_num += 1\n",
    "                self.backword_pass(batch_x, batch_y, neuron_outputs, learning_rate)\n",
    "            \n",
    "            average_loss = total_loss/batch_num\n",
    "            \n",
    "            # now let's make predictions on validation dataset \n",
    "            validation_predictions = self.predict(X_val)\n",
    "            validation_accuracy = np.mean(validation_predictions == np.argmax(y_val, axis = 1))\n",
    "\n",
    "            # loging to wandb\n",
    "            wandb.log({'epoch': epoch , 'train_loss': average_loss, 'val_accuracy': validation_accuracy})\n",
    "            print(f\"epoch: {epoch}, train_loss:{average_loss:.4f}, val_accuracy: {validation_accuracy:.4f}\")\n",
    "            \n",
    "    def predict(self, X): \n",
    "        # this will predict class labels for the passed data\n",
    "        neuron_outputs = self.forward_pass(X)\n",
    "        return np.argmax(neuron_outputs[-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0021f582-d6b0-4fbc-af70-b8601b88346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the data ready to train the model\n",
    "\n",
    "# Splitting the trainig data into train and validation\n",
    "\n",
    "indices = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_size = 50000\n",
    "train_x = train_images[indices[:train_size]]\n",
    "train_y = train_labels[indices[:train_size]]\n",
    "val_x = train_images[indices[train_size:]]\n",
    "val_y = train_labels[indices[train_size:]]\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "val_x = val_x.reshape(val_x.shape[0], -1)\n",
    "\n",
    "# train_x.ravel()\n",
    "# val_y.ravel()\n",
    "\n",
    "# converting y's into one hot vector\n",
    "num_classes = 10\n",
    "train_y = np.eye(num_classes)[train_y]\n",
    "val_y = np.eye(num_classes)[val_y]\n",
    "\n",
    "# let's do it for test data as well\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)\n",
    "test_labels = np.eye(num_classes)[test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "6956e596-cb08-4165-a3c6-e7233347af42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/backprop_scratch/runs/cj4wa5mn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2a9061f0890>"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing hyperparms in wandb\n",
    "wandb.init(project='backprop_scratch', \n",
    "           config={ 'Learning_rate' : 0.001, \n",
    "                    'epochs' : 50, \n",
    "                    'batch_size' : 32, \n",
    "                    'layer_size' : [784, 128, 64, 10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "478a84ac-1300-4a9f-9651-fd5b9957be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Learning_rate': 0.001, 'epochs': 50, 'batch_size': 32, 'layer_size': [784, 128, 64, 10]}\n"
     ]
    }
   ],
   "source": [
    "print(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "accc57be-f35a-4af8-9f6c-8a1bce905e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss:2.0760, val_accuracy: 0.5380\n",
      "epoch: 1, train_loss:1.7583, val_accuracy: 0.6070\n",
      "epoch: 2, train_loss:1.5751, val_accuracy: 0.6683\n",
      "epoch: 3, train_loss:1.4275, val_accuracy: 0.6889\n",
      "epoch: 4, train_loss:1.3024, val_accuracy: 0.7123\n",
      "epoch: 5, train_loss:1.1972, val_accuracy: 0.7220\n",
      "epoch: 6, train_loss:1.1085, val_accuracy: 0.7334\n",
      "epoch: 7, train_loss:1.0324, val_accuracy: 0.7481\n",
      "epoch: 8, train_loss:0.9685, val_accuracy: 0.7574\n",
      "epoch: 9, train_loss:0.9135, val_accuracy: 0.7640\n",
      "epoch: 10, train_loss:0.8666, val_accuracy: 0.7711\n",
      "epoch: 11, train_loss:0.8257, val_accuracy: 0.7819\n",
      "epoch: 12, train_loss:0.7904, val_accuracy: 0.7832\n",
      "epoch: 13, train_loss:0.7597, val_accuracy: 0.7908\n",
      "epoch: 14, train_loss:0.7315, val_accuracy: 0.7936\n",
      "epoch: 15, train_loss:0.7079, val_accuracy: 0.7939\n",
      "epoch: 16, train_loss:0.6854, val_accuracy: 0.8016\n",
      "epoch: 17, train_loss:0.6657, val_accuracy: 0.8017\n",
      "epoch: 18, train_loss:0.6471, val_accuracy: 0.8044\n",
      "epoch: 19, train_loss:0.6320, val_accuracy: 0.8069\n",
      "epoch: 20, train_loss:0.6161, val_accuracy: 0.8092\n",
      "epoch: 21, train_loss:0.6028, val_accuracy: 0.8090\n",
      "epoch: 22, train_loss:0.5904, val_accuracy: 0.8116\n",
      "epoch: 23, train_loss:0.5782, val_accuracy: 0.8125\n",
      "epoch: 24, train_loss:0.5684, val_accuracy: 0.8171\n",
      "epoch: 25, train_loss:0.5585, val_accuracy: 0.8212\n",
      "epoch: 26, train_loss:0.5496, val_accuracy: 0.8192\n",
      "epoch: 27, train_loss:0.5405, val_accuracy: 0.8198\n",
      "epoch: 28, train_loss:0.5330, val_accuracy: 0.8222\n",
      "epoch: 29, train_loss:0.5258, val_accuracy: 0.8245\n",
      "epoch: 30, train_loss:0.5190, val_accuracy: 0.8276\n",
      "epoch: 31, train_loss:0.5111, val_accuracy: 0.8246\n",
      "epoch: 32, train_loss:0.5065, val_accuracy: 0.8245\n",
      "epoch: 33, train_loss:0.5024, val_accuracy: 0.8261\n",
      "epoch: 34, train_loss:0.4958, val_accuracy: 0.8300\n",
      "epoch: 35, train_loss:0.4886, val_accuracy: 0.8276\n",
      "epoch: 36, train_loss:0.4854, val_accuracy: 0.8340\n",
      "epoch: 37, train_loss:0.4799, val_accuracy: 0.8305\n",
      "epoch: 38, train_loss:0.4754, val_accuracy: 0.8309\n",
      "epoch: 39, train_loss:0.4705, val_accuracy: 0.8330\n",
      "epoch: 40, train_loss:0.4665, val_accuracy: 0.8320\n",
      "epoch: 41, train_loss:0.4645, val_accuracy: 0.8325\n",
      "epoch: 42, train_loss:0.4608, val_accuracy: 0.8351\n",
      "epoch: 43, train_loss:0.4547, val_accuracy: 0.8349\n",
      "epoch: 44, train_loss:0.4547, val_accuracy: 0.8382\n",
      "epoch: 45, train_loss:0.4532, val_accuracy: 0.8369\n",
      "epoch: 46, train_loss:0.4481, val_accuracy: 0.8366\n",
      "epoch: 47, train_loss:0.4426, val_accuracy: 0.8386\n",
      "epoch: 48, train_loss:0.4407, val_accuracy: 0.8373\n",
      "epoch: 49, train_loss:0.4401, val_accuracy: 0.8384\n",
      "test_accuracy: 0.8283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = wandb.config\n",
    "\n",
    "# now let's create and train the network\n",
    "model = backprop_from_scratch(config.layer_size)\n",
    "\n",
    "model.train(train_x, train_y, val_x, val_y, config.epochs, config.Learning_rate, config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8b169-a595-4675-8738-92de53c0f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's evaluate on the test set\n",
    "test_predictions = model.predict(test_images) \n",
    "test_accuracy = np.mean(test_predictions == np.argmax(test_labels, axis = 1))\n",
    "print(f\"test_accuracy:{test_accuracy: .4f}\") \n",
    "wandb.log({'test_accuracy': test_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83794a88-f0d8-4108-a61d-0da7a1a530cd",
   "metadata": {},
   "source": [
    "**Question 3(24 Marks):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5a63c-7432-498c-94c6-0bd93941a87f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Optimization algorithms to implement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361b770-947c-47aa-b054-a72c3a241323",
   "metadata": {},
   "source": [
    "- **sgd:** make update with respect to a batch of the datapoints.\n",
    "- **momentum based gradient descent:** will make an update using momentum at each step.\n",
    "- **nestrov accelerated gradient descent:** why not to move a little based of momentum we've.\n",
    "- **rms prop:** make learning rate inversly prop to expnentionally accumulating update histroy in that particular direction.\n",
    "- **adam:**\n",
    "- **nadam:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9ce1f-8a8e-460b-a35b-943fa9af18c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### vanila gradient descent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "853e7e01-66ea-4a6a-88f2-d7435820a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# defining a backprop_from_scratch to do all.\n",
    "class backprop_from_scratch:\n",
    "\n",
    "    # define constructor\n",
    "    def __init__(self, layer_size):\n",
    "        # initialise the neural network\n",
    "        self.weights, self.biases = [], []\n",
    "        self.num_layers = len(layer_size)\n",
    "        self.layer_sizes = layer_size\n",
    "        self.initialize_params()\n",
    "        \n",
    "    def initialize_params(self):\n",
    "        # let's use He initialization for weights and set values of bias equals to zero\n",
    "        for i in range(self.num_layers-1):\n",
    "            w = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1]) * np.sqrt(2/self.layer_sizes[i])\n",
    "            b = np.zeros((1, self.layer_sizes[i+1]))\n",
    "            self.weights.append(w) \n",
    "            self.biases.append(b) \n",
    "            \n",
    "    def forward_pass(self, data_X):\n",
    "        neuron_outputs = [data_X]\n",
    "        # pass thorugh hidden layers\n",
    "        for i in range(self.num_layers - 2): \n",
    "            \n",
    "            # print(\"ran\")\n",
    "            # print(neuron_outputs[-1].shape)\n",
    "            # print(self.weights[i].shape)\n",
    "            # print(self.biases[i].shape)\n",
    "            \n",
    "            a = np.dot(neuron_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            h = self.sigmoid(a)\n",
    "            neuron_outputs.append(h)\n",
    "        # pass thorugh the output layer\n",
    "        a = np.dot(neuron_outputs[-1], self.weights[-1]) + self.biases[-1]\n",
    "        output = self.softmax(a)\n",
    "        neuron_outputs.append(output)\n",
    "        return neuron_outputs\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        # clipping it bw -500 to 500 \n",
    "        return 1 / (1 + np.exp(-np.clip(X, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x*(1-x) \n",
    "        \n",
    "    def softmax(self, X): \n",
    "        # clipping it for numerical stability\n",
    "        exp_x = np.exp(X - np.max(X, axis = 1, keepdims=True))\n",
    "        return exp_x/np.sum(exp_x, axis = 1, keepdims=True)\n",
    "    \n",
    "    def backword_pass(self, X, y, neuron_outputs, learning_rate):\n",
    "        \n",
    "        # compute the gradient at given value of params\n",
    "        batch_size = len(X)\n",
    "        \n",
    "        # computing gradies with repect to the output layer \n",
    "        delta = neuron_outputs[-1] - y\n",
    "        \n",
    "        # computing gradient with respect to hidden layers\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            \n",
    "            dw = np.dot(neuron_outputs[i].T, delta) / batch_size\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / batch_size\n",
    "            \n",
    "            if i>0: # because computing delta for i=0 will be absolutely un-necessary.\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(neuron_outputs[i])\n",
    "\n",
    "            # making an update\n",
    "            self.weights[i] -= dw * learning_rate\n",
    "            self.biases[i] -= db * learning_rate\n",
    "        \n",
    "    # function to train the network\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate, batch_size):\n",
    "        for epoch in range(epochs): \n",
    "            # first shuffle the training data\n",
    "            # print(X_train.shape[0])\n",
    "            \n",
    "            indices = np.random.permutation(X_train.shape[0]) \n",
    "            X_train_permuted = X_train[indices]\n",
    "            y_train_permuted = y_train[indices]\n",
    "            \n",
    "            total_loss = 0\n",
    "            batch_num = 0\n",
    "            \n",
    "            # let's make a update for a mini batch\n",
    "            for i in range(0, X_train.shape[0], batch_size): \n",
    "                batch_x = X_train_permuted[i: i + batch_size]\n",
    "                batch_y = y_train_permuted[i: i + batch_size]\n",
    "                neuron_outputs = self.forward_pass(batch_x)\n",
    "                loss = -np.mean(np.sum(batch_y * np.log(neuron_outputs[-1] + 1e-10), axis = 1)) # to prevent numerical underflow\n",
    "                total_loss += loss\n",
    "                batch_num += 1\n",
    "                self.backword_pass(batch_x, batch_y, neuron_outputs, learning_rate)\n",
    "            \n",
    "            average_loss = total_loss/batch_num\n",
    "            \n",
    "            # now let's make predictions on validation dataset \n",
    "            validation_predictions = self.predict(X_val)\n",
    "            validation_accuracy = np.mean(validation_predictions == np.argmax(y_val, axis = 1))\n",
    "\n",
    "            # loging to wandb\n",
    "            wandb.log({'epoch': epoch , 'train_loss': average_loss, 'val_accuracy': validation_accuracy})\n",
    "            print(f\"epoch: {epoch}, train_loss:{average_loss:.4f}, val_accuracy: {validation_accuracy:.4f}\")\n",
    "            \n",
    "    def predict(self, X): \n",
    "        # this will predict class labels for the passed data\n",
    "        neuron_outputs = self.forward_pass(X)\n",
    "        return np.argmax(neuron_outputs[-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9e37e87e-f499-41a6-ae05-71d64ed8fe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Learning_rate': 0.5, 'epochs': 50, 'batch_size': 50000, 'layer_size': [784, 128, 64, 10]}\n"
     ]
    }
   ],
   "source": [
    "# initializing hyperparms in wandb\n",
    "wandb.init(project='vanilla_gradient_descent', \n",
    "           config={ 'Learning_rate' : 0.01, \n",
    "                    'epochs' : 50000, \n",
    "                    'batch_size' : 32, \n",
    "                    'layer_size' : [784, 128, 64, 10]})\n",
    "config.Learning_rate = 0.5\n",
    "print(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "41126661-f67a-4620-9fb7-c217865fc50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "epoch: 0, train_loss:2.5263, val_accuracy: 0.1755\n",
      "epoch: 1, train_loss:2.1899, val_accuracy: 0.3493\n",
      "epoch: 2, train_loss:2.0400, val_accuracy: 0.4653\n",
      "epoch: 3, train_loss:1.9601, val_accuracy: 0.4679\n",
      "epoch: 4, train_loss:1.8783, val_accuracy: 0.5827\n",
      "epoch: 5, train_loss:1.8046, val_accuracy: 0.4852\n",
      "epoch: 6, train_loss:1.7489, val_accuracy: 0.5587\n",
      "epoch: 7, train_loss:1.7054, val_accuracy: 0.4694\n",
      "epoch: 8, train_loss:1.6741, val_accuracy: 0.5997\n",
      "epoch: 9, train_loss:1.6056, val_accuracy: 0.5574\n",
      "epoch: 10, train_loss:1.5576, val_accuracy: 0.5615\n",
      "epoch: 11, train_loss:1.5438, val_accuracy: 0.5261\n",
      "epoch: 12, train_loss:1.5140, val_accuracy: 0.5946\n",
      "epoch: 13, train_loss:1.4517, val_accuracy: 0.5943\n",
      "epoch: 14, train_loss:1.3844, val_accuracy: 0.6291\n",
      "epoch: 15, train_loss:1.3447, val_accuracy: 0.6087\n",
      "epoch: 16, train_loss:1.3231, val_accuracy: 0.6265\n",
      "epoch: 17, train_loss:1.2831, val_accuracy: 0.6410\n",
      "epoch: 18, train_loss:1.2440, val_accuracy: 0.6360\n",
      "epoch: 19, train_loss:1.2199, val_accuracy: 0.6514\n",
      "epoch: 20, train_loss:1.1843, val_accuracy: 0.6573\n",
      "epoch: 21, train_loss:1.1541, val_accuracy: 0.6673\n",
      "epoch: 22, train_loss:1.1446, val_accuracy: 0.6276\n",
      "epoch: 23, train_loss:1.1493, val_accuracy: 0.6191\n",
      "epoch: 24, train_loss:1.2014, val_accuracy: 0.5493\n",
      "epoch: 25, train_loss:1.2749, val_accuracy: 0.4979\n",
      "epoch: 26, train_loss:1.3579, val_accuracy: 0.5444\n",
      "epoch: 27, train_loss:1.2525, val_accuracy: 0.5946\n",
      "epoch: 28, train_loss:1.1965, val_accuracy: 0.6551\n",
      "epoch: 29, train_loss:1.0867, val_accuracy: 0.7095\n",
      "epoch: 30, train_loss:1.0070, val_accuracy: 0.7108\n",
      "epoch: 31, train_loss:0.9751, val_accuracy: 0.7285\n",
      "epoch: 32, train_loss:0.9512, val_accuracy: 0.7207\n",
      "epoch: 33, train_loss:0.9362, val_accuracy: 0.7392\n",
      "epoch: 34, train_loss:0.9216, val_accuracy: 0.7221\n",
      "epoch: 35, train_loss:0.9148, val_accuracy: 0.7412\n",
      "epoch: 36, train_loss:0.9078, val_accuracy: 0.7162\n",
      "epoch: 37, train_loss:0.9091, val_accuracy: 0.7273\n",
      "epoch: 38, train_loss:0.9005, val_accuracy: 0.7101\n",
      "epoch: 39, train_loss:0.9077, val_accuracy: 0.7309\n",
      "epoch: 40, train_loss:0.8893, val_accuracy: 0.7005\n",
      "epoch: 41, train_loss:0.8934, val_accuracy: 0.7401\n",
      "epoch: 42, train_loss:0.8689, val_accuracy: 0.7213\n",
      "epoch: 43, train_loss:0.8603, val_accuracy: 0.7526\n",
      "epoch: 44, train_loss:0.8477, val_accuracy: 0.7210\n",
      "epoch: 45, train_loss:0.8547, val_accuracy: 0.7463\n",
      "epoch: 46, train_loss:0.8403, val_accuracy: 0.7059\n",
      "epoch: 47, train_loss:0.8525, val_accuracy: 0.7478\n",
      "epoch: 48, train_loss:0.8388, val_accuracy: 0.6935\n",
      "epoch: 49, train_loss:0.8437, val_accuracy: 0.7247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = wandb.config\n",
    "\n",
    "# now let's create and train the network\n",
    "model = backprop_from_scratch(config.layer_size)\n",
    "\n",
    "print(config.batch_size)\n",
    "# passing batch size = size of the data\n",
    "model.train(train_x, train_y, val_x, val_y, config.epochs, config.Learning_rate, config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d1b625b3-4aa4-4df3-9ae4-bd79844d2730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.7174\n"
     ]
    }
   ],
   "source": [
    "# now let's evaluate on the test set\n",
    "test_predictions = model.predict(test_images) \n",
    "test_accuracy = np.mean(test_predictions == np.argmax(test_labels, axis = 1))\n",
    "print(f\"test_accuracy:{test_accuracy: .4f}\") \n",
    "wandb.log({'test_accuracy': test_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c0ce6-f14c-4192-8a48-b68191abf459",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### momentum based sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "32d8d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted the same code for sgd for momentum sgd\n",
    "\n",
    " \n",
    "import numpy as np \n",
    "\n",
    "# defining a backprop_from_scratch to do all.\n",
    "class backprop_from_scratch:\n",
    "\n",
    "    # define constructor\n",
    "    def __init__(self, layer_size):\n",
    "        \n",
    "        # initialise the neural network\n",
    "        self.weights, self.biases = [], []\n",
    "        self.num_layers = len(layer_size)\n",
    "        self.layer_sizes = layer_size\n",
    "        self.initialize_params()\n",
    "\n",
    "        # delarin and initializing the velocity for weights and bias\n",
    "        self.weights_velocity = []\n",
    "        self.bias_velocity = []\n",
    "\n",
    "        self.weights_velocity = [np.zeros_like(w) for w in self.weights]\n",
    "        self.bias_velocity = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "        # parameter of momentum\n",
    "        self.beta = 0.90\n",
    "\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        # let's use He initialization for weights and set values of bias equals to zero\n",
    "        for i in range(self.num_layers-1):\n",
    "            w = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1]) * np.sqrt(2/self.layer_sizes[i])\n",
    "            b = np.zeros((1, self.layer_sizes[i+1]))\n",
    "            self.weights.append(w) \n",
    "            self.biases.append(b) \n",
    "            \n",
    "    def forward_pass(self, data_X):\n",
    "        neuron_outputs = [data_X]\n",
    "        # pass thorugh hidden layers\n",
    "        for i in range(self.num_layers - 2): \n",
    "            \n",
    "            # print(\"ran\")\n",
    "            # print(neuron_outputs[-1].shape)\n",
    "            # print(self.weights[i].shape)\n",
    "            # print(self.biases[i].shape)\n",
    "            \n",
    "            a = np.dot(neuron_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            h = self.sigmoid(a)\n",
    "            neuron_outputs.append(h)\n",
    "        # pass thorugh the output layer\n",
    "        a = np.dot(neuron_outputs[-1], self.weights[-1]) + self.biases[-1]\n",
    "        output = self.softmax(a)\n",
    "        neuron_outputs.append(output)\n",
    "        return neuron_outputs\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        # clipping it bw -500 to 500 \n",
    "        return 1 / (1 + np.exp(-np.clip(X, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x*(1-x) \n",
    "        \n",
    "    def softmax(self, X): \n",
    "        # clipping it for numerical stability\n",
    "        exp_x = np.exp(X - np.max(X, axis = 1, keepdims=True))\n",
    "        return exp_x/np.sum(exp_x, axis = 1, keepdims=True)\n",
    "    \n",
    "    def backword_pass(self, X, y, neuron_outputs, learning_rate):\n",
    "        \n",
    "        # compute the gradient at given value of params\n",
    "        batch_size = len(X)\n",
    "        \n",
    "        # computing gradies with repect to the output layer \n",
    "        delta = neuron_outputs[-1] - y\n",
    "        \n",
    "        # computing gradient with respect to hidden layers\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            \n",
    "            dw = np.dot(neuron_outputs[i].T, delta) / batch_size\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / batch_size\n",
    "            \n",
    "            if i>0: # because computing delta for i=0 will be absolutely un-necessary.\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(neuron_outputs[i])\n",
    "\n",
    "            # computing the momentum\n",
    "            self.weights_velocity[i] = self.beta * self.weights_velocity[i] + dw\n",
    "            self.bias_velocity[i] = self.beta * self.bias_velocity[i] + db\n",
    "\n",
    "            # making an update\n",
    "            self.weights[i] -= self.weights_velocity[i] * learning_rate\n",
    "            self.biases[i] -= self.bias_velocity[i] * learning_rate\n",
    "\n",
    "    # function to train the network\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate, batch_size):\n",
    "\n",
    "        weights_velocity, bias_velocity, beta = 0, 0, 0.95\n",
    "        for epoch in range(epochs): \n",
    "            # First shuffle the training data\n",
    "            # print(X_train.shape[0])\n",
    "            \n",
    "            indices = np.random.permutation(X_train.shape[0]) \n",
    "            X_train_permuted = X_train[indices]\n",
    "            y_train_permuted = y_train[indices]\n",
    "            \n",
    "            total_loss = 0\n",
    "            batch_num = 0\n",
    "            \n",
    "            # let's make a update for a mini batch\n",
    "            for i in range(0, X_train.shape[0], batch_size): \n",
    "                batch_x = X_train_permuted[i: i + batch_size]\n",
    "                batch_y = y_train_permuted[i: i + batch_size]\n",
    "                neuron_outputs = self.forward_pass(batch_x)\n",
    "                loss = -np.mean(np.sum(batch_y * np.log(neuron_outputs[-1] + 1e-10), axis = 1)) # to prevent numberical underflow\n",
    "                total_loss += loss\n",
    "                batch_num += 1\n",
    "                self.backword_pass(batch_x, batch_y, neuron_outputs, learning_rate)\n",
    "            \n",
    "            average_loss = total_loss/batch_num\n",
    "            \n",
    "            # now let's make predictions on validation dataset \n",
    "            validation_predictions = self.predict(X_val)\n",
    "            validation_accuracy = np.mean(validation_predictions == np.argmax(y_val, axis = 1))\n",
    "\n",
    "            # loging to wandb\n",
    "            wandb.log({'epoch': epoch , 'train_loss': average_loss, 'val_accuracy': validation_accuracy})\n",
    "            print(f\"epoch: {epoch}, train_loss:{average_loss:.4f}, val_accuracy: {validation_accuracy:.4f}\")\n",
    "            \n",
    "    def predict(self, X): \n",
    "        # this will predict class labels for the passed data\n",
    "        neuron_outputs = self.forward_pass(X)\n",
    "        return np.argmax(neuron_outputs[-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5bb5770b-66c7-490b-9d10-b1d3514dd9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Learning_rate': 0.001, 'epochs': 50, 'batch_size': 32, 'layer_size': [784, 128, 64, 10]}\n",
      "epoch: 0, train_loss:1.4112, val_accuracy: 0.7204\n",
      "epoch: 1, train_loss:0.8460, val_accuracy: 0.7577\n",
      "epoch: 2, train_loss:0.7022, val_accuracy: 0.7636\n",
      "epoch: 3, train_loss:0.6540, val_accuracy: 0.7860\n",
      "epoch: 4, train_loss:0.6333, val_accuracy: 0.7882\n",
      "epoch: 5, train_loss:0.6228, val_accuracy: 0.7847\n",
      "epoch: 6, train_loss:0.6147, val_accuracy: 0.7978\n",
      "epoch: 7, train_loss:0.6110, val_accuracy: 0.7903\n",
      "epoch: 8, train_loss:0.6089, val_accuracy: 0.7949\n",
      "epoch: 9, train_loss:0.5990, val_accuracy: 0.7893\n",
      "epoch: 10, train_loss:0.6107, val_accuracy: 0.7803\n",
      "epoch: 11, train_loss:0.6105, val_accuracy: 0.7844\n",
      "epoch: 12, train_loss:0.6037, val_accuracy: 0.7792\n",
      "epoch: 13, train_loss:0.5969, val_accuracy: 0.7907\n",
      "epoch: 14, train_loss:0.5965, val_accuracy: 0.7779\n",
      "epoch: 15, train_loss:0.6075, val_accuracy: 0.7869\n",
      "epoch: 16, train_loss:0.6169, val_accuracy: 0.7813\n",
      "epoch: 17, train_loss:0.6178, val_accuracy: 0.7818\n",
      "epoch: 18, train_loss:0.6072, val_accuracy: 0.7991\n",
      "epoch: 19, train_loss:0.6172, val_accuracy: 0.7947\n",
      "epoch: 20, train_loss:0.6071, val_accuracy: 0.7905\n",
      "epoch: 21, train_loss:0.5928, val_accuracy: 0.7886\n",
      "epoch: 22, train_loss:0.6055, val_accuracy: 0.7595\n",
      "epoch: 23, train_loss:0.5925, val_accuracy: 0.7794\n",
      "epoch: 24, train_loss:0.6026, val_accuracy: 0.7873\n",
      "epoch: 25, train_loss:0.5986, val_accuracy: 0.7973\n",
      "epoch: 26, train_loss:0.5902, val_accuracy: 0.8069\n",
      "epoch: 27, train_loss:0.5951, val_accuracy: 0.7850\n",
      "epoch: 28, train_loss:0.6113, val_accuracy: 0.7899\n",
      "epoch: 29, train_loss:0.6289, val_accuracy: 0.7655\n",
      "epoch: 30, train_loss:0.6372, val_accuracy: 0.7743\n",
      "epoch: 31, train_loss:0.6281, val_accuracy: 0.7764\n",
      "epoch: 32, train_loss:0.6119, val_accuracy: 0.7729\n",
      "epoch: 33, train_loss:0.6120, val_accuracy: 0.7751\n",
      "epoch: 34, train_loss:0.6253, val_accuracy: 0.7721\n",
      "epoch: 35, train_loss:0.6352, val_accuracy: 0.7740\n",
      "epoch: 36, train_loss:0.6255, val_accuracy: 0.7912\n",
      "epoch: 37, train_loss:0.6212, val_accuracy: 0.7913\n",
      "epoch: 38, train_loss:0.6110, val_accuracy: 0.7835\n",
      "epoch: 39, train_loss:0.6150, val_accuracy: 0.7550\n",
      "epoch: 40, train_loss:0.6104, val_accuracy: 0.7655\n",
      "epoch: 41, train_loss:0.6127, val_accuracy: 0.7717\n",
      "epoch: 42, train_loss:0.6323, val_accuracy: 0.7749\n",
      "epoch: 43, train_loss:0.6313, val_accuracy: 0.7723\n",
      "epoch: 44, train_loss:0.6275, val_accuracy: 0.7313\n",
      "epoch: 45, train_loss:0.6242, val_accuracy: 0.7520\n",
      "epoch: 46, train_loss:0.6263, val_accuracy: 0.7676\n",
      "epoch: 47, train_loss:0.6120, val_accuracy: 0.7738\n",
      "epoch: 48, train_loss:0.6218, val_accuracy: 0.7899\n",
      "epoch: 49, train_loss:0.6249, val_accuracy: 0.7724\n"
     ]
    }
   ],
   "source": [
    "# initializing hyperparms in wandb\n",
    "wandb.init(project='backprop_scratch', \n",
    "           config={ 'Learning_rate' : 0.001, \n",
    "                    'epochs' : 50, \n",
    "                    'batch_size' : 32, \n",
    "                    'layer_size' : [784, 128, 64, 10],\n",
    "                  'optimizer': ['sgd', 'momentum sgd'],\n",
    "                  'beta': 0.90})\n",
    "\n",
    "print(wandb.config)\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# now let's create and train the network\n",
    "model = backprop_from_scratch(config.layer_size)\n",
    "\n",
    "model.train(train_x, train_y, val_x, val_y, config.epochs, config.Learning_rate, config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee1ef9b8-1fe8-49e6-b5e8-6e062fc607ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.7657\n"
     ]
    }
   ],
   "source": [
    "# now let's evaluate on the test set\n",
    "test_predictions = model.predict(test_images) \n",
    "test_accuracy = np.mean(test_predictions == np.argmax(test_labels, axis = 1))\n",
    "print(f\"test_accuracy:{test_accuracy: .4f}\") \n",
    "wandb.log({'test_accuracy': test_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd366f29-8241-4a6b-b705-daa636db7957",
   "metadata": {},
   "source": [
    "#### NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01c8f0-3eed-4857-8d0b-bc23309f8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted the same code for sgd for momentum sgd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# defining a backprop_from_scratch to do all.\n",
    "class backprop_from_scratch:\n",
    "\n",
    "    # define constructor\n",
    "    def __init__(self, layer_size):\n",
    "        \n",
    "        # initialise the neural network\n",
    "        self.weights, self.biases = [], []\n",
    "        self.num_layers = len(layer_size)\n",
    "        self.layer_sizes = layer_size\n",
    "        self.initialize_params()\n",
    "\n",
    "        # delarin and initializing the velocity for weights and bias\n",
    "        self.weights_velocity = []\n",
    "        self.bias_velocity = []\n",
    "\n",
    "        self.weights_velocity = [np.zeros_like(w) for w in self.weights]\n",
    "        self.bias_velocity = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "        # parameter of momentum\n",
    "        self.beta = 0.90\n",
    "\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        # let's use He initialization for weights and set values of bias equals to zero\n",
    "        for i in range(self.num_layers-1):\n",
    "            w = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1]) * np.sqrt(2/self.layer_sizes[i])\n",
    "            b = np.zeros((1, self.layer_sizes[i+1]))\n",
    "            self.weights.append(w) \n",
    "            self.biases.append(b) \n",
    "            \n",
    "    def forward_pass(self, data_X):\n",
    "        neuron_outputs = [data_X]\n",
    "        # pass thorugh hidden layers\n",
    "        for i in range(self.num_layers - 2): \n",
    "            \n",
    "            # print(\"ran\")\n",
    "            # print(neuron_outputs[-1].shape)\n",
    "            # print(self.weights[i].shape)\n",
    "            # print(self.biases[i].shape)\n",
    "            \n",
    "            a = np.dot(neuron_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            h = self.sigmoid(a)\n",
    "            neuron_outputs.append(h)\n",
    "        # pass thorugh the output layer\n",
    "        a = np.dot(neuron_outputs[-1], self.weights[-1]) + self.biases[-1]\n",
    "        output = self.softmax(a)\n",
    "        neuron_outputs.append(output)\n",
    "        return neuron_outputs\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        # clipping it bw -500 to 500 \n",
    "        return 1 / (1 + np.exp(-np.clip(X, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x*(1-x) \n",
    "        \n",
    "    def softmax(self, X): \n",
    "        # clipping it for numerical stability\n",
    "        exp_x = np.exp(X - np.max(X, axis = 1, keepdims=True))\n",
    "        return exp_x/np.sum(exp_x, axis = 1, keepdims=True)\n",
    "    \n",
    "    def backword_pass(self, X, y, neuron_outputs, learning_rate):\n",
    "        \n",
    "        # compute the gradient at given value of params\n",
    "        batch_size = len(X)\n",
    "        \n",
    "        # Computing gradies with repect to the output layer \n",
    "        delta = neuron_outputs[-1] - y\n",
    "        \n",
    "        # computing gradient with respect to hidden layers\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "\n",
    "            # neuron_ouputs depend on the data, which we have computed in the forward pass\n",
    "            # but delta will depend on on the weight matrices\n",
    "    \n",
    "            dw = np.dot(neuron_outputs[i].T, delta) / batch_size\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / batch_size\n",
    "            \n",
    "            if i>0: # because computing delta for i=0 will be absolutely un-necessary.\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(neuron_outputs[i])\n",
    "\n",
    "            # computing the momentum\n",
    "            self.weights_velocity[i] = self.beta * self.weights_velocity[i] + dw\n",
    "            self.bias_velocity[i] = self.beta * self.bias_velocity[i] + db\n",
    "\n",
    "            # making an update\n",
    "            self.weights[i] -= self.weights_velocity[i] * learning_rate\n",
    "            self.biases[i] -= self.bias_velocity[i] * learning_rate\n",
    "\n",
    "    # function to train the network\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate, batch_size):\n",
    "\n",
    "        weights_velocity, bias_velocity, beta = 0, 0, 0.95\n",
    "        for epoch in range(epochs): \n",
    "            # First shuffle the training data\n",
    "            # print(X_train.shape[0])\n",
    "            \n",
    "            indices = np.random.permutation(X_train.shape[0]) \n",
    "            X_train_permuted = X_train[indices]\n",
    "            y_train_permuted = y_train[indices]\n",
    "            \n",
    "            total_loss = 0\n",
    "            batch_num = 0\n",
    "            \n",
    "            # let's make a update for a mini batch\n",
    "            for i in range(0, X_train.shape[0], batch_size): \n",
    "                batch_x = X_train_permuted[i: i + batch_size]\n",
    "                batch_y = y_train_permuted[i: i + batch_size]\n",
    "                neuron_outputs = self.forward_pass(batch_x)\n",
    "                loss = -np.mean(np.sum(batch_y * np.log(neuron_outputs[-1] + 1e-10), axis = 1)) # to prevent numberical underflow\n",
    "                total_loss += loss\n",
    "                batch_num += 1\n",
    "                self.backword_pass(batch_x, batch_y, neuron_outputs, learning_rate)\n",
    "            \n",
    "            average_loss = total_loss/batch_num\n",
    "            \n",
    "            # now let's make predictions on validation dataset \n",
    "            validation_predictions = self.predict(X_val)\n",
    "            validation_accuracy = np.mean(validation_predictions == np.argmax(y_val, axis = 1))\n",
    "\n",
    "            # loging to wandb\n",
    "            wandb.log({'epoch': epoch , 'train_loss': average_loss, 'val_accuracy': validation_accuracy})\n",
    "            print(f\"epoch: {epoch}, train_loss:{average_loss:.4f}, val_accuracy: {validation_accuracy:.4f}\")\n",
    "            \n",
    "    def predict(self, X): \n",
    "        # this will predict class labels for the passed data\n",
    "        neuron_outputs = self.forward_pass(X)\n",
    "        return np.argmax(neuron_outputs[-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de7955-08d6-473f-81df-16af615d5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing hyperparms in wandb\n",
    "wandb.init(project='backprop_scratch', \n",
    "           config={ 'Learning_rate' : 0.001, \n",
    "                    'epochs' : 50, \n",
    "                    'batch_size' : 32, \n",
    "                    'layer_size' : [784, 128, 64, 10],\n",
    "                  'optimizer': ['sgd', 'momentum sgd'],\n",
    "                  'beta': 0.90})\n",
    "\n",
    "print(wandb.config)\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# now let's create and train the network\n",
    "model = backprop_from_scratch(config.layer_size)\n",
    "\n",
    "model.train(train_x, train_y, val_x, val_y, config.epochs, config.Learning_rate, config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1d57f-91af-4b44-ac0e-858ad8891c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's evaluate on the test set\n",
    "test_predictions = model.predict(test_images) \n",
    "test_accuracy = np.mean(test_predictions == np.argmax(test_labels, axis = 1))\n",
    "print(f\"test_accuracy:{test_accuracy: .4f}\") \n",
    "wandb.log({'test_accuracy': test_accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f47b7-a8de-451c-a033-6ec446649b42",
   "metadata": {},
   "source": [
    "question is how are going to compute gradient exactly at a little bit farther distance in the direction of the momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcddb4-e2c0-4546-9ebc-5bdcf08e83db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
